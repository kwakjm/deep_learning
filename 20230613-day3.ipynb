{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피마 인디언 데이터 분석하기\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('./data/pima-indians-diabetes3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 5개의 정보 확인\n",
    "df.head()\n",
    "\n",
    "# 당뇨 환자의 수\n",
    "print(df['diabetes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 자료의 통계 정보  -> describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 속성별 상관관계 확인\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap() 그래프로 상관관계 확인\n",
    "colormap = plt.cm.gist_heat\n",
    "plt.figure(figsize=(8,8))  #  그래프의 크기 지정\n",
    "sns.heatmap(df.corr(), annot=True, cmap=colormap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plasma와 bmi 속성을 따로 추출해서  상관관계를 자세히 보고자 함 -> 히스토그램으로 \n",
    "# 1. plasma에 대해 당뇨와 정상에 대한 히스토그램 그리기\n",
    "plt.hist(x=[df.plasma[df.diabetes==0], df.plasma[df.diabetes==1]], bins=30,\n",
    "         histtype='barstacked', label=['normal', 'diabetes'])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2. bmi에 대해 당뇨와 정상에 대한 히스토그램 그리기\n",
    "plt.hist(x=[df.bmi[df.diabetes==0], df.bmi[df.diabetes==1]], bins=30,\n",
    "         histtype='barstacked', label=['normal', 'diabetes'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피마 인디언의 당뇨 예측 분석 - 딥러닝\n",
    "#  속성 0 ~ -1\n",
    "X = df.iloc[:, 0:-1]  # 마지막 속성이 클래스임 , 마지막 속성을 제외하고 속성 추출\n",
    "print(X.head())\n",
    "y = df.iloc[:, -1]  # 마지막 속성을 클래스로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# input-> 8 ,처음 layer -> 12, 두번째 layer -> 8, 출력층 -> 1\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X.shape[1], activation='relu', name='Dense_1'))  # 입력층, layer_1\n",
    "model.add(Dense(8, activation='relu', name='Dense_2'))   # layer_2\n",
    "model.add(Dense(1, activation='sigmoid', name='Dense_3'))  # 출력층\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # 컴파일 설정\n",
    "model.fit(X, y, epochs=200, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss와 accuracy 값 확인\n",
    "print(model.history.history['loss'][-1], model.history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류인 자료의 분석\n",
    "# iris 데이터를 분석\n",
    "df = pd.read_csv('./data/iris3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species 가 클래스, 4개의 속성을 가진 자료임을 확인\n",
    "# species와 다른 속성들간의 관계를 그래프로 작성\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y로 분리\n",
    "X = df.iloc[:, 0:-1]  # 속성 분리\n",
    "y =df.iloc[:, -1]    # 클래스 분리\n",
    "y.info()  # object이므로 -> one-hot encoding을 통해 숫자로 변형시킴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(y,drop_first=True)\n",
    "y = pd.get_dummies(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 자료로 모델링\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))  # 입력층, 첫번째 층\n",
    "model.add(Dense(8, activation='relu'))  # 중간층 ( 2번째)\n",
    "model.add(Dense(3, activation='softmax')) # 출력층, 마지막 결과가 카테고리\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predict_data = np.array(X.iloc[len(X)//2,:]).reshape(1,-1)\n",
    "\n",
    "print(y.iloc[len(y)//2, :], model.predict(predict_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predict_data = np.array(X.iloc[len(X)//2,:]).reshape(1,-1)\n",
    "predict_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 12)                60        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 5)                 65        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 1ms/step - loss: 10.8993\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 6.4300\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.7536\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.1651\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.2211\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.8265\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7368\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7137\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7025\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6960\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6904\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6861\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6821\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6785\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6755\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6729\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6704\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6676\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6653\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6631\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6594\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6572\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6547\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6524\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6499\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6474\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6447\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6418\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6379\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6350\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6333\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6289\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6253\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6229\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6196\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6177\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6146\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6124\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6127\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6068\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6053\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6041\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6006\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6028\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5970\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5939\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5919\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5895\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5890\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5871\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5856\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5833\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5818\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5824\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5809\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5766\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5787\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5762\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5786\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5751\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5728\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5733\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5727\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5712\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5703\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5723\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5697\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5694\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5740\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5708\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5687\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5663\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5657\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5675\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5694\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5702\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5692\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5644\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5646\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5612\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5637\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5636\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5612\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5688\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5613\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5601\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5625\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5593\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5608\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5593\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5590\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5661\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5587\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5596\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5599\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25821c2c0a0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피마 인디언 자료중에 당뇨에 영향을 끼치는 속성만 추출해서 딥러닝 실행\n",
    "df = pd.read_csv('./data/pima-indians-diabetes3.csv')\n",
    "df.head(2)\n",
    "\n",
    "# 'plasma', 'pressure', 'bmi', 'age' 컬럼의 정보만 가져와서 딥러닝 실행\n",
    "features = ['plasma', 'pressure', 'bmi', 'age']\n",
    "X = df.loc[ :, features]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model1.add(Dense(5,activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model1.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유방암 자료를 가지고 딥러닝 학습\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "Data = load_breast_cancer()   # X <- data,  y <- target (  층은 3개층 )\n",
    "features = Data['feature_names']\n",
    "X = Data['data']\n",
    "y = Data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_wine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
